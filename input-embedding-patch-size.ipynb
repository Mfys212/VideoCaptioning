{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 9483701,
          "sourceType": "datasetVersion",
          "datasetId": 5768982
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.15.0\n",
        "!pip install pycocoevalcap"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2025-03-27T05:17:56.509725Z",
          "iopub.execute_input": "2025-03-27T05:17:56.509946Z",
          "iopub.status.idle": "2025-03-27T05:18:21.590241Z",
          "shell.execute_reply.started": "2025-03-27T05:17:56.509924Z",
          "shell.execute_reply": "2025-03-27T05:18:21.589395Z"
        },
        "trusted": true,
        "id": "yIr4WT21Kzmc",
        "outputId": "55b37310-a1f5-45cc-b9b0-22372a557aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting keras==2.15.0\n  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 3.3.3\n    Uninstalling keras-3.3.3:\n      Successfully uninstalled keras-3.3.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0\nCollecting pycocoevalcap\n  Downloading pycocoevalcap-1.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting pycocotools>=2.0.2 (from pycocoevalcap)\n  Downloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from pycocotools>=2.0.2->pycocoevalcap) (3.7.5)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pycocotools>=2.0.2->pycocoevalcap) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.16.0)\nDownloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pycocotools-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.8/427.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pycocotools, pycocoevalcap\nSuccessfully installed pycocoevalcap-1.2 pycocotools-2.0.8\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:21.591416Z",
          "iopub.execute_input": "2025-03-27T05:18:21.591655Z",
          "iopub.status.idle": "2025-03-27T05:18:22.700242Z",
          "shell.execute_reply.started": "2025-03-27T05:18:21.591634Z",
          "shell.execute_reply": "2025-03-27T05:18:22.699446Z"
        },
        "id": "JAnenCy0Kzme",
        "outputId": "1fb5e10b-3e4d-46ba-abb7-bb24b68f0649"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Thu Mar 27 05:18:22 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   38C    P8              9W /   70W |       1MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import islice, cycle\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import multiprocessing\n",
        "cpu_count = multiprocessing.cpu_count()\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.applications as pretrained\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from scipy.spatial.distance import cosine\n",
        "from pycocoevalcap.cider.cider import Cider\n",
        "from IPython.display import HTML, display\n",
        "from base64 import b64encode\n",
        "\n",
        "# seed = 111\n",
        "# np.random.seed(seed)\n",
        "# tf.random.set_seed(seed)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:22.702468Z",
          "iopub.execute_input": "2025-03-27T05:18:22.702746Z",
          "iopub.status.idle": "2025-03-27T05:18:40.085325Z",
          "shell.execute_reply.started": "2025-03-27T05:18:22.702721Z",
          "shell.execute_reply": "2025-03-27T05:18:40.084669Z"
        },
        "id": "7eV52lAQKzmg",
        "outputId": "aa52b91e-5a0d-47c6-af29-888cbe6012cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-03-27 05:18:27.114687: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-03-27 05:18:27.114818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-03-27 05:18:27.355751: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:40.086279Z",
          "iopub.execute_input": "2025-03-27T05:18:40.086745Z",
          "iopub.status.idle": "2025-03-27T05:18:41.476453Z",
          "shell.execute_reply.started": "2025-03-27T05:18:40.086722Z",
          "shell.execute_reply": "2025-03-27T05:18:41.475583Z"
        },
        "trusted": true,
        "id": "ipQ1ijkdKzmh",
        "outputId": "02703d62-f47b-43ff-8529-309cd62055bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of devices: 2\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the videos\n",
        "VIDEOS_PATH = \"/kaggle/input/videodata/YouTubeClips/YouTubeClips\"\n",
        "CAPTIONS_PATH = \"/kaggle/input/videodata/MSVD-indonesian.txt\"\n",
        "FRAMES_STORAGE_PATH = \"/kaggle/working/extracted_frames\"\n",
        "\n",
        "# Desired image dimensions\n",
        "IMAGE_SIZE = (224, 224)\n",
        "\n",
        "MAX_FRAMES = 16\n",
        "\n",
        "NUM_CAPTIONS = 40\n",
        "\n",
        "PATCH_SIZE = (16, 16, 16)\n",
        "NUM_PATCH = int((MAX_FRAMES*(IMAGE_SIZE[0])**2) / (PATCH_SIZE[0]*PATCH_SIZE[1]**2))\n",
        "\n",
        "# Vocabulary size\n",
        "VOCAB_SIZE = 10000\n",
        "\n",
        "# Fixed length allowed for any sequence\n",
        "SEQ_LENGTH = 40\n",
        "\n",
        "# Dimension for embeddings\n",
        "EMBED_DIM = 512\n",
        "\n",
        "NUM_HEADS = 8\n",
        "\n",
        "# Dimension for models\n",
        "D_MODELS = int(EMBED_DIM / NUM_HEADS)\n",
        "\n",
        "# Other training parameters\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 100\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:41.477466Z",
          "iopub.execute_input": "2025-03-27T05:18:41.477690Z",
          "iopub.status.idle": "2025-03-27T05:18:41.483113Z",
          "shell.execute_reply.started": "2025-03-27T05:18:41.477672Z",
          "shell.execute_reply": "2025-03-27T05:18:41.482324Z"
        },
        "trusted": true,
        "id": "DCOdc1USKzmi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "exs = (\".mp4\", \".avi\", \".mov\", \".mkv\", \".wmv\", \".flv\", \".webm\", \".mpeg\", \".mpg\", \".3gp\")\n",
        "\n",
        "# Load captions data\n",
        "def load_captions_data(filename):\n",
        "    \"\"\"Loads captions (text) data and maps them to corresponding videos.\"\"\"\n",
        "    with open(filename) as caption_file:\n",
        "        caption_data = caption_file.readlines()\n",
        "        caption_mapping = {}\n",
        "        text_data = []\n",
        "        videos_to_skip = set()\n",
        "\n",
        "        for line in caption_data:\n",
        "            line = line.rstrip(\"\\n\")\n",
        "            parts = line.split(\" \", 1)\n",
        "            if len(parts) < 1:\n",
        "                continue\n",
        "            video_name, caption = parts\n",
        "            caption = caption.strip()\n",
        "\n",
        "            # Skip empty captions\n",
        "            if not caption or caption == 0:\n",
        "                continue\n",
        "\n",
        "            tokens = caption.split()\n",
        "            if len(tokens) < 1 or len(tokens) > SEQ_LENGTH:\n",
        "                videos_to_skip.add(video_name)\n",
        "                continue\n",
        "\n",
        "            video_name = os.path.join(VIDEOS_PATH, video_name.strip() + '.avi')\n",
        "\n",
        "            if video_name.endswith(exs) and video_name not in videos_to_skip:\n",
        "                caption = \"<start> \" + caption + \" <end>\"\n",
        "                text_data.append(caption)\n",
        "\n",
        "                if video_name in caption_mapping:\n",
        "                    caption_mapping[video_name].append(caption)\n",
        "                else:\n",
        "                    caption_mapping[video_name] = [caption]\n",
        "\n",
        "        for video_name in videos_to_skip:\n",
        "            if video_name in caption_mapping:\n",
        "                del caption_mapping[video_name]\n",
        "\n",
        "        return caption_mapping, text_data\n",
        "\n",
        "# Split data into training and validation sets\n",
        "def train_val_split(caption_data, train_size=0.8, shuffle=False):\n",
        "    all_videos = list(caption_data.keys())\n",
        "    if shuffle:\n",
        "        np.random.shuffle(all_videos)\n",
        "    train_size = int(len(caption_data) * train_size)\n",
        "    training_data = {\n",
        "        video_name: caption_data[video_name] for video_name in all_videos[:train_size]\n",
        "    }\n",
        "    validation_data = {\n",
        "        video_name: caption_data[video_name] for video_name in all_videos[train_size:]\n",
        "    }\n",
        "    return training_data, validation_data\n",
        "\n",
        "# Load the dataset\n",
        "captions_mapping, text_data = load_captions_data(CAPTIONS_PATH)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_data, valid_data = train_val_split(captions_mapping)\n",
        "print(\"Number of training samples: \", len(train_data))\n",
        "print(\"Number of validation samples: \", len(valid_data))\n",
        "print(f\"Unique word count: {len(set(' '.join(text_data).split()))}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:41.484386Z",
          "iopub.execute_input": "2025-03-27T05:18:41.484683Z",
          "iopub.status.idle": "2025-03-27T05:18:41.885434Z",
          "shell.execute_reply.started": "2025-03-27T05:18:41.484657Z",
          "shell.execute_reply": "2025-03-27T05:18:41.884526Z"
        },
        "trusted": true,
        "id": "TOQ0QnL7Kzmi",
        "outputId": "b0f7cc99-bfe0-4050-e961-de9153b20ba7"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of training samples:  1576\nNumber of validation samples:  394\nUnique word count: 9452\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lengths = [len(sentence.split()) for sentence in text_data]\n",
        "length_counts = Counter(lengths)\n",
        "\n",
        "lengths_unique = list(length_counts.keys())\n",
        "frequencies = list(length_counts.values())\n",
        "\n",
        "print(\"min length:\", min(lengths_unique))\n",
        "print(\"max length:\", max(lengths_unique))\n",
        "\n",
        "# Visualisasikan dengan bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(lengths_unique, frequencies, color='skyblue')\n",
        "plt.xlabel('Panjang Sequence')\n",
        "plt.ylabel('Frekuensi')\n",
        "plt.xticks(np.arange(min(lengths_unique), max(lengths_unique) + 1, 1))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:41.886365Z",
          "iopub.execute_input": "2025-03-27T05:18:41.886595Z",
          "iopub.status.idle": "2025-03-27T05:18:42.340793Z",
          "shell.execute_reply.started": "2025-03-27T05:18:41.886576Z",
          "shell.execute_reply": "2025-03-27T05:18:42.339985Z"
        },
        "id": "B9yqJgBVKzmj",
        "outputId": "5cf910c1-fe41-4359-c894-1ba4d562147f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "min length: 3\nmax length: 40\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "merge = {**train_data, **valid_data}\n",
        "num_caption = [len(captions) for captions in merge.values()]\n",
        "\n",
        "min_caption = min(num_caption)\n",
        "max_caption = max(num_caption)\n",
        "\n",
        "print(f\"Minimum number of captions: {min_caption}\")\n",
        "print(f\"Maximum number of captions: {max_caption}\")\n",
        "\n",
        "sns.histplot(num_caption, bins=range(1, max(num_caption) + 2), color='skyblue', kde=False)\n",
        "plt.xlabel('Jumlah Caption per Video')\n",
        "plt.ylabel('Frekuensi')\n",
        "plt.title('Distribusi Jumlah Caption per Video')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:42.342029Z",
          "iopub.execute_input": "2025-03-27T05:18:42.342760Z",
          "iopub.status.idle": "2025-03-27T05:18:42.688643Z",
          "shell.execute_reply.started": "2025-03-27T05:18:42.342727Z",
          "shell.execute_reply": "2025-03-27T05:18:42.687681Z"
        },
        "id": "_HmoKeDeKzmj",
        "outputId": "cb538f56-1be6-4fc1-faeb-b2ba6c52ee74"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Minimum number of captions: 18\nMaximum number of captions: 81\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n  with pd.option_context('mode.use_inf_as_na', True):\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_string):\n",
        "    return tf.strings.lower(input_string)\n",
        "\n",
        "vectorization = TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=SEQ_LENGTH,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "vectorization.adapt(text_data)\n",
        "\n",
        "# vocab = vectorization.get_vocabulary()\n",
        "# MASK_TOKEN = \"[MASK]\"\n",
        "# vocab = vocab + [MASK_TOKEN]\n",
        "# MASK_TOKEN_ID = len(vocab) - 1\n",
        "# inverse_vocab = {word: idx for idx, word in enumerate(vocab)}\n",
        "# vectorization.set_vocabulary(vocab)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:42.690893Z",
          "iopub.execute_input": "2025-03-27T05:18:42.691119Z",
          "iopub.status.idle": "2025-03-27T05:18:46.319147Z",
          "shell.execute_reply.started": "2025-03-27T05:18:42.691100Z",
          "shell.execute_reply": "2025-03-27T05:18:46.318456Z"
        },
        "id": "PymhjSLrKzmj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def save_video_frames(video_path, output_dir, size=IMAGE_SIZE, max_frames=MAX_FRAMES):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    if total_frames <= max_frames:\n",
        "        selected_frames = list(range(total_frames))\n",
        "    else:\n",
        "        selected_frames = np.linspace(0, total_frames - 1, max_frames, dtype=int)\n",
        "\n",
        "    for idx, frame_idx in enumerate(selected_frames):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#         frame = cv2.resize(frame, size)\n",
        "        frame_filename = os.path.join(output_dir, f\"frame_{idx:04d}.jpg\")\n",
        "        cv2.imwrite(frame_filename, frame)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "if not os.path.exists(FRAMES_STORAGE_PATH):\n",
        "    video_paths = list(captions_mapping.keys())\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=cpu_count+2) as executor:\n",
        "        list(tqdm(executor.map(\n",
        "            lambda video_path: save_video_frames(video_path, os.path.join(FRAMES_STORAGE_PATH, os.path.basename(video_path).split('.')[0])),\n",
        "            video_paths\n",
        "        ), total=len(video_paths), desc=\"Saving frames\"))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:18:46.320148Z",
          "iopub.execute_input": "2025-03-27T05:18:46.320402Z",
          "iopub.status.idle": "2025-03-27T05:29:13.112886Z",
          "shell.execute_reply.started": "2025-03-27T05:18:46.320374Z",
          "shell.execute_reply": "2025-03-27T05:29:13.111795Z"
        },
        "id": "gnwQlpzdKzmk",
        "outputId": "d9986f9f-bcd2-439d-f8f7-61ba9e1ddd19"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Saving frames: 100%|██████████| 1970/1970 [10:26<00:00,  3.14it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Decode and resize video\n",
        "# def process_frame(frame, size):\n",
        "#     \"\"\"Resize and convert a single frame.\"\"\"\n",
        "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#     frame = tf.convert_to_tensor(frame, dtype=tf.float32) / 255.0\n",
        "#     frame = tf.image.resize(frame, size)\n",
        "#     return frame\n",
        "\n",
        "# def decode_and_resize_video(video_path, size=IMAGE_SIZE, max_frames=MAX_FRAMES):\n",
        "#     video_path = video_path.numpy().decode('utf-8')\n",
        "#     cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "#     total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "#     if total_frames <= max_frames:\n",
        "#         selected_frames = list(range(total_frames))\n",
        "#     else:\n",
        "#         selected_frames = np.linspace(0, total_frames - 1, max_frames, dtype=int)\n",
        "\n",
        "#     frames = []\n",
        "#     for idx in selected_frames:\n",
        "#         cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
        "#         ret, frame = cap.read()\n",
        "#         if not ret:\n",
        "#             break\n",
        "#         frames.append(frame)\n",
        "\n",
        "#     cap.release()\n",
        "\n",
        "#     processed_frames = list(map(lambda frame: process_frame(frame, size), frames))\n",
        "\n",
        "#     # Padding with zeros if necessary\n",
        "#     if len(processed_frames) < max_frames:\n",
        "#         padding = [tf.zeros((size[0], size[1], 3), dtype=tf.float32)] * (max_frames - len(processed_frames))\n",
        "#         processed_frames.extend(padding)\n",
        "\n",
        "#     video = tf.stack(processed_frames, axis=0)\n",
        "#     return video\n",
        "\n",
        "# # TensorFlow wrapper for video processing\n",
        "# def tf_decode_and_resize_video(video_path):\n",
        "#     video = tf.py_function(\n",
        "#         func=decode_and_resize_video,\n",
        "#         inp=[video_path],\n",
        "#         Tout=tf.float32\n",
        "#     )\n",
        "\n",
        "#     video.set_shape((MAX_FRAMES, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "#     return video\n",
        "\n",
        "# # Read video\n",
        "# def read_video(video_path, size=IMAGE_SIZE):\n",
        "#     video = tf_decode_and_resize_video(video_path)\n",
        "#     return video\n",
        "\n",
        "\n",
        "def load_frames_from_directory(directory, size=IMAGE_SIZE, max_frames=MAX_FRAMES):\n",
        "    try:\n",
        "        directory = directory.numpy().decode('utf-8')\n",
        "    except:\n",
        "        pass\n",
        "    frame_files = sorted(glob(os.path.join(directory, \"*.jpg\")))\n",
        "    frames = []\n",
        "    for frame_file in frame_files[:max_frames]:\n",
        "        frame = tf.io.read_file(frame_file)\n",
        "        frame = tf.image.decode_jpeg(frame, channels=3)\n",
        "        frame = tf.image.resize(frame, size)\n",
        "        frames.append(frame)\n",
        "\n",
        "    if len(frames) < max_frames:\n",
        "        padding = [tf.zeros((size[0], size[1], 3), dtype=tf.float32)] * (max_frames - len(frames))\n",
        "        frames.extend(padding)\n",
        "\n",
        "    video_tensor = tf.stack(frames, axis=0)\n",
        "    return video_tensor\n",
        "\n",
        "def tf_load_frames_from_directory(directory):\n",
        "    video_tensor = tf.py_function(\n",
        "        func=load_frames_from_directory,\n",
        "        inp=[directory],\n",
        "        Tout=tf.float32\n",
        "    )\n",
        "\n",
        "    video_tensor.set_shape((MAX_FRAMES, IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "    return video_tensor\n",
        "\n",
        "def pad_captions(captions, max_captions=NUM_CAPTIONS):\n",
        "    captions_unique = list(set(captions))\n",
        "\n",
        "    if len(captions_unique) > max_captions:\n",
        "        captions_padded = captions_unique[:max_captions]\n",
        "    else:\n",
        "        captions_padded = list(islice(cycle(captions_unique), max_captions))\n",
        "\n",
        "    return captions_padded\n",
        "\n",
        "def make_dataset_from_frames(frame_directories, captions, split=\"train\"):\n",
        "    frame_dataset = tf.data.Dataset.from_tensor_slices(frame_directories).map(\n",
        "        tf_load_frames_from_directory, num_parallel_calls=AUTOTUNE\n",
        "    )\n",
        "\n",
        "    captions_padded = list(map(pad_captions, captions))\n",
        "    cap_dataset = tf.data.Dataset.from_tensor_slices(captions_padded).map(\n",
        "        vectorization, num_parallel_calls=AUTOTUNE\n",
        "    )\n",
        "\n",
        "    dataset = tf.data.Dataset.zip((frame_dataset, cap_dataset))\n",
        "    dataset = dataset.batch(BATCH_SIZE).shuffle(256).prefetch(AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "train_frame_dirs = [os.path.join(FRAMES_STORAGE_PATH, os.path.basename(video).split('.')[0]) for video in train_data.keys()]\n",
        "valid_frame_dirs = [os.path.join(FRAMES_STORAGE_PATH, os.path.basename(video).split('.')[0]) for video in valid_data.keys()]\n",
        "\n",
        "train_dataset = make_dataset_from_frames(train_frame_dirs, list(train_data.values()))\n",
        "valid_dataset = make_dataset_from_frames(valid_frame_dirs, list(valid_data.values()))\n",
        "train_dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:29:13.114235Z",
          "iopub.execute_input": "2025-03-27T05:29:13.114537Z",
          "iopub.status.idle": "2025-03-27T05:29:13.442522Z",
          "shell.execute_reply.started": "2025-03-27T05:29:13.114515Z",
          "shell.execute_reply": "2025-03-27T05:29:13.441462Z"
        },
        "id": "Voi4dq2-Kzmk",
        "outputId": "77d9dd02-f4cf-4084-b44a-d86b2b18e63d"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 16, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, None, 40), dtype=tf.int64, name=None))>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Patch Size nd=D"
      ],
      "metadata": {
        "id": "EA4TLOGCKzml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_frame, patch_height, patch_width, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.projection = layers.Conv3D(\n",
        "            filters=embed_dim,\n",
        "            kernel_size=(num_frame, patch_height, patch_width),\n",
        "            strides=(num_frame, patch_height, patch_width),\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        self.flatten = layers.Reshape(target_shape=(-1, embed_dim))\n",
        "\n",
        "    def call(self, videos):\n",
        "        projected_patches = self.projection(videos)\n",
        "        flattened_patches = self.flatten(projected_patches)\n",
        "        return flattened_patches\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "    def __init__(self, sequence_length, embed_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.positional_encoding = self.add_weight(\n",
        "            name=\"positional_encoding\",\n",
        "            shape=(sequence_length, embed_dim),\n",
        "            initializer=tf.keras.initializers.RandomNormal(),\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        length = tf.shape(inputs)[1]\n",
        "        pos_encoding = tf.expand_dims(self.positional_encoding[:length, :], axis=0)\n",
        "        return tf.tile(pos_encoding, [batch_size, 1, 1])\n",
        "\n",
        "class TransformerEncoderBlock(tf.keras.Model):\n",
        "    def __init__(self, d_models, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.tconv1 = layers.Conv3D(4, (1, 3, 3), strides=(1, 2, 2), padding='same')\n",
        "        self.tconv2 = layers.Conv3D(3, (1, 3, 3), strides=(1, 2, 2), padding='same')\n",
        "        self.sconv1 = layers.Conv3D(4, (3, 1, 1), strides=(2, 1, 1), padding='same')\n",
        "        self.sconv2 = layers.Conv3D(3, (3, 1, 1), strides=(2, 1, 1), padding='same')\n",
        "        self.flatten = layers.TimeDistributed(layers.Flatten())\n",
        "        self.linear = layers.Dense(EMBED_DIM)\n",
        "\n",
        "        self.patch_embedding = PatchEmbedding(EMBED_DIM, PATCH_SIZE[0]//4, PATCH_SIZE[1], PATCH_SIZE[2])\n",
        "\n",
        "        self.frame_positional_encoding = PositionalEncoding(\n",
        "            sequence_length=MAX_FRAMES, embed_dim=EMBED_DIM\n",
        "        )\n",
        "        self.patch_positional_encoding = PositionalEncoding(\n",
        "            sequence_length=NUM_PATCH, embed_dim=EMBED_DIM\n",
        "        )\n",
        "\n",
        "        self.attention_frame1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_models, dropout=0.1\n",
        "        )\n",
        "        self.attention_frame2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_models, dropout=0.1\n",
        "        )\n",
        "\n",
        "        self.attention_cross1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_models, dropout=0.1\n",
        "        )\n",
        "        self.attention_cross2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_models, dropout=0.1\n",
        "        )\n",
        "\n",
        "        self.layernorm_frame1 = layers.LayerNormalization()\n",
        "        self.layernorm_frame2 = layers.LayerNormalization()\n",
        "\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.layernorm_4 = layers.LayerNormalization()\n",
        "\n",
        "        self.dense_1 = layers.Dense(EMBED_DIM, activation=\"gelu\")\n",
        "        self.densel_1 = layers.Dense(EMBED_DIM)\n",
        "        self.dense_2 = layers.Dense(EMBED_DIM, activation=\"gelu\")\n",
        "        self.densel_2 = layers.Dense(EMBED_DIM)\n",
        "\n",
        "        self.dropout_1 = layers.Dropout(0.1)\n",
        "        self.dropout_2 = layers.Dropout(0.1)\n",
        "\n",
        "        self.out = layers.Dense(EMBED_DIM, activation=\"gelu\")\n",
        "\n",
        "    def call(self, inputs, training=False, mask=None):\n",
        "        frame = self.flatten(self.tconv2(self.tconv1(inputs)))\n",
        "        frame = self.linear(frame)\n",
        "        Zt = layers.Add()([frame, self.frame_positional_encoding(frame)])\n",
        "\n",
        "        patch = self.patch_embedding(self.sconv2(self.sconv1(inputs)))\n",
        "        Zs = layers.Add()([patch, self.patch_positional_encoding(patch)])\n",
        "        Zst = tf.concat([Zs, Zt], axis=1)\n",
        "\n",
        "        # EncoderBlock 1\n",
        "        attention_output1 = self.attention_frame1(\n",
        "            query=Zt,\n",
        "            value=Zst,\n",
        "            key=Zst,\n",
        "            attention_mask=None,\n",
        "            training=training,\n",
        "        )\n",
        "        Zt = self.layernorm_frame1(layers.Add()([Zt, attention_output1]))\n",
        "        Zts = tf.concat([Zs, Zt], axis=1)\n",
        "        attention_output2 = self.attention_cross1(\n",
        "            query=Zs,\n",
        "            value=Zts,\n",
        "            key=Zts,\n",
        "            attention_mask=None,\n",
        "            training=training,\n",
        "        )\n",
        "        Zs = self.layernorm_1(layers.Add()([Zs, attention_output2]))\n",
        "        inputs = self.dense_1(Zs)\n",
        "        inputs = self.dropout_1(inputs, training=training)\n",
        "        inputs = self.densel_1(inputs)\n",
        "        Zs = self.layernorm_2(layers.Add()([inputs, Zs]))\n",
        "        inputsf = self.dense_1(Zt)\n",
        "        inputsf = self.dropout_1(inputsf, training=training)\n",
        "        inputsf = self.densel_1(inputsf)\n",
        "        Zt = self.layernorm_2(layers.Add()([inputsf, Zt]))\n",
        "\n",
        "        # EncoderBlock 2\n",
        "        attention_output1 = self.attention_frame2(\n",
        "            query=Zt,\n",
        "            value=Zt,\n",
        "            key=Zt,\n",
        "            attention_mask=None,\n",
        "            training=training,\n",
        "        )\n",
        "        Zt = self.layernorm_frame2(layers.Add()([Zt, attention_output1]))\n",
        "        Zts = tf.concat([Zs, Zt], axis=1)\n",
        "        attention_output2 = self.attention_cross2(\n",
        "            query=Zs,\n",
        "            value=Zts,\n",
        "            key=Zts,\n",
        "            attention_mask=None,\n",
        "            training=training,\n",
        "        )\n",
        "        Zs = self.layernorm_3(layers.Add()([Zs, attention_output2]))\n",
        "        inputs = self.dense_2(Zs)\n",
        "        inputs = self.dropout_2(inputs, training=training)\n",
        "        inputs = self.densel_2(inputs)\n",
        "        Zs = self.layernorm_4(layers.Add()([inputs, Zs]))\n",
        "        inputsf = self.dense_2(Zt)\n",
        "        inputsf = self.dropout_2(inputsf, training=training)\n",
        "        inputsf = self.densel_2(inputsf)\n",
        "        Zt = self.layernorm_4(layers.Add()([inputsf, Zt]))\n",
        "\n",
        "        # output\n",
        "        out = tf.concat([Zs, Zt], axis=1)\n",
        "        out = self.out(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class TransformerDecoderBlock(tf.keras.Model):\n",
        "    def __init__(self, d_models, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=VOCAB_SIZE, output_dim=EMBED_DIM\n",
        "        )\n",
        "        self.embed_scale = tf.math.sqrt(tf.cast(EMBED_DIM, tf.float32))\n",
        "\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            sequence_length=SEQ_LENGTH, embed_dim=EMBED_DIM\n",
        "        )\n",
        "\n",
        "        self.attention_m = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_models, dropout=0.1\n",
        "        )\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_models, dropout=0.1\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=d_models, dropout=0.1\n",
        "        )\n",
        "\n",
        "        self.ffn_layer_1 = layers.Dense(EMBED_DIM, activation=\"gelu\")\n",
        "        self.ffn_layerl_1 = layers.Dense(EMBED_DIM)\n",
        "        self.ffn_layer_2 = layers.Dense(EMBED_DIM, activation=\"gelu\")\n",
        "        self.ffn_layerl_2 = layers.Dense(EMBED_DIM)\n",
        "\n",
        "        self.ffn_layer_out = layers.Dense(EMBED_DIM)\n",
        "\n",
        "        self.dropout_1 = layers.Dropout(0.1)\n",
        "        self.dropout_2 = layers.Dropout(0.1)\n",
        "        self.supports_masking = True\n",
        "\n",
        "        self.layernorm_m = layers.LayerNormalization()\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.layernorm_4 = layers.LayerNormalization()\n",
        "\n",
        "        self.out = layers.Dense(VOCAB_SIZE)\n",
        "\n",
        "    def call(self, inp, training=False):\n",
        "        inputs, encoder_outputs, mask = inp\n",
        "        inputs = self.token_embeddings(inputs)\n",
        "        inputs = inputs * self.embed_scale\n",
        "        inputs = layers.Add()([inputs, self.positional_encoding(inputs)])\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, :, tf.newaxis], dtype=tf.int32)\n",
        "            combined_mask = tf.cast(mask[:, tf.newaxis, :], dtype=tf.int32)\n",
        "            combined_mask = tf.minimum(combined_mask, causal_mask)\n",
        "\n",
        "        # DecoderBlock1\n",
        "        attention_output = self.attention_m(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=combined_mask,\n",
        "            training=training,\n",
        "        )\n",
        "        out = self.layernorm_m(layers.Add()([inputs, attention_output]))\n",
        "\n",
        "        attention_output = self.attention_1(\n",
        "            query=out,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "            training=training,\n",
        "        )\n",
        "        out = self.layernorm_1(layers.Add()([out, attention_output]))\n",
        "        ffn_out = self.ffn_layer_1(out)\n",
        "        ffn_out = self.dropout_1(ffn_out, training=training)\n",
        "        ffn_out = self.ffn_layerl_1(ffn_out)\n",
        "        ffn_out = self.layernorm_2(layers.Add()([ffn_out, out]))\n",
        "\n",
        "        # DecoderBlock2\n",
        "        attention_output = self.attention_2(\n",
        "            query=ffn_out,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "            training=training,\n",
        "        )\n",
        "        out = self.layernorm_3(layers.Add()([ffn_out, attention_output]))\n",
        "        ffn_out = self.ffn_layer_2(out)\n",
        "        ffn_out = self.dropout_2(ffn_out, training=training)\n",
        "        ffn_out = self.ffn_layerl_2(ffn_out)\n",
        "        ffn_out = self.layernorm_4(layers.Add()([ffn_out, out]))\n",
        "\n",
        "        # preds\n",
        "        ffn_out = self.ffn_layer_out(ffn_out)\n",
        "        preds = self.out(ffn_out)\n",
        "        return preds\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "class MainModel(keras.Model):\n",
        "    def __init__(self, encoder, decoder, num_captions_per_video=NUM_CAPTIONS):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "        self.acc_tracker = keras.metrics.Mean(name=\"accuracy\")\n",
        "        self.num_captions_per_video = num_captions_per_video\n",
        "\n",
        "    def calculate_loss(self, y_true, y_pred, mask):\n",
        "        loss = self.loss(y_true, y_pred)\n",
        "        mask = tf.cast(mask, dtype=loss.dtype)\n",
        "        loss *= mask\n",
        "        return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
        "\n",
        "    def calculate_accuracy(self, y_true, y_pred, mask):\n",
        "        accuracy = tf.equal(y_true, tf.argmax(y_pred, axis=2))\n",
        "        accuracy = tf.math.logical_and(mask, accuracy)\n",
        "        accuracy = tf.cast(accuracy, dtype=tf.float32)\n",
        "        mask = tf.cast(mask, dtype=tf.float32)\n",
        "        return tf.reduce_sum(accuracy) / tf.reduce_sum(mask)\n",
        "\n",
        "    def _compute_caption_loss_and_acc(self, encoder_out, batch_seq, training=True):\n",
        "        batch_seq_inp = batch_seq[:, :-1]\n",
        "        batch_seq_true = batch_seq[:, 1:]\n",
        "        mask = tf.math.not_equal(batch_seq_true, 0)\n",
        "        batch_seq_pred = self.decoder(\n",
        "            [batch_seq_inp, encoder_out, mask], training=training\n",
        "        )\n",
        "        loss = self.calculate_loss(batch_seq_true, batch_seq_pred, mask)\n",
        "        acc = self.calculate_accuracy(batch_seq_true, batch_seq_pred, mask)\n",
        "        return loss, acc\n",
        "\n",
        "    def _compute_loss_and_acc_for_captions(self, encoder_out, batch_seq, training):\n",
        "        def compute_loss_acc(i):\n",
        "            return self._compute_caption_loss_and_acc(\n",
        "                encoder_out, batch_seq[:, i, :], training=training\n",
        "            )\n",
        "\n",
        "        loss_acc_pairs = tf.map_fn(compute_loss_acc, tf.range(self.num_captions_per_video), dtype=(tf.float32, tf.float32))\n",
        "\n",
        "        batch_loss = tf.reduce_sum(loss_acc_pairs[0])\n",
        "        batch_acc = tf.reduce_mean(loss_acc_pairs[1])\n",
        "\n",
        "        return batch_loss, batch_acc\n",
        "\n",
        "    def train_step(self, batch_data):\n",
        "        batch_video, batch_seq = batch_data\n",
        "        batch_loss = 0\n",
        "        batch_acc = 0\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            encoder_out = self.encoder(batch_video, training=True)\n",
        "            batch_loss, batch_acc = self._compute_loss_and_acc_for_captions(encoder_out, batch_seq, training=True)\n",
        "\n",
        "        train_vars = (\n",
        "            self.encoder.trainable_variables +\n",
        "            self.decoder.trainable_variables\n",
        "        )\n",
        "\n",
        "        grads = tape.gradient(batch_loss, train_vars)\n",
        "        self.optimizer.apply_gradients(zip(grads, train_vars))\n",
        "\n",
        "        self.loss_tracker.update_state(batch_loss)\n",
        "        self.acc_tracker.update_state(batch_acc)\n",
        "\n",
        "        return {\"seq_loss\": self.loss_tracker.result(), \"seq_acc\": self.acc_tracker.result()}\n",
        "\n",
        "    def test_step(self, batch_data):\n",
        "        batch_video, batch_seq = batch_data\n",
        "        batch_loss = 0\n",
        "        batch_acc = 0\n",
        "\n",
        "        encoder_out = self.encoder(batch_video, training=False)\n",
        "        batch_loss, batch_acc = self._compute_loss_and_acc_for_captions(encoder_out, batch_seq, training=False)\n",
        "\n",
        "        self.loss_tracker.update_state(batch_loss)\n",
        "        self.acc_tracker.update_state(batch_acc)\n",
        "\n",
        "        return {\"seq_loss\": self.loss_tracker.result(), \"seq_acc\": self.acc_tracker.result()}\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.loss_tracker, self.acc_tracker]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:29:13.443963Z",
          "iopub.execute_input": "2025-03-27T05:29:13.444191Z",
          "iopub.status.idle": "2025-03-27T05:29:13.693506Z",
          "shell.execute_reply.started": "2025-03-27T05:29:13.444172Z",
          "shell.execute_reply": "2025-03-27T05:29:13.692757Z"
        },
        "id": "mbZHHd4-Kzmm"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    encoder = TransformerEncoderBlock(d_models=D_MODELS, num_heads=NUM_HEADS)\n",
        "    encoder.build(input_shape=(None, MAX_FRAMES, *IMAGE_SIZE, 3))\n",
        "    decoder = TransformerDecoderBlock(d_models=D_MODELS, num_heads=NUM_HEADS)\n",
        "    decoder.build([(None, None), (None, NUM_PATCH, EMBED_DIM), (None, None)])\n",
        "    model = MainModel(\n",
        "        encoder=encoder, decoder=decoder\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:29:13.694814Z",
          "iopub.execute_input": "2025-03-27T05:29:13.695369Z",
          "iopub.status.idle": "2025-03-27T05:29:16.334219Z",
          "shell.execute_reply.started": "2025-03-27T05:29:13.695345Z",
          "shell.execute_reply": "2025-03-27T05:29:16.333319Z"
        },
        "id": "1HjRU2vAKzmn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainable_vars = model.trainable_variables\n",
        "total_params = 0\n",
        "\n",
        "for var in trainable_vars:\n",
        "    var_params = tf.size(var).numpy()\n",
        "    total_params += var_params\n",
        "    print(f\"{var.name}: {var.shape} -> {var_params} params\")\n",
        "\n",
        "print(f\"Total trainable parameters: {total_params}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:29:16.335339Z",
          "iopub.execute_input": "2025-03-27T05:29:16.335629Z",
          "iopub.status.idle": "2025-03-27T05:29:16.372636Z",
          "shell.execute_reply.started": "2025-03-27T05:29:16.335609Z",
          "shell.execute_reply": "2025-03-27T05:29:16.371771Z"
        },
        "id": "1KC4d2-bKzmn",
        "outputId": "f5aa0bae-9f8a-4607-843a-b90585c41f8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "conv3d/kernel:0: (1, 3, 3, 3, 4) -> 108 params\nconv3d/bias:0: (4,) -> 4 params\nconv3d_1/kernel:0: (1, 3, 3, 4, 3) -> 108 params\nconv3d_1/bias:0: (3,) -> 3 params\nconv3d_2/kernel:0: (3, 1, 1, 3, 4) -> 36 params\nconv3d_2/bias:0: (4,) -> 4 params\nconv3d_3/kernel:0: (3, 1, 1, 4, 3) -> 36 params\nconv3d_3/bias:0: (3,) -> 3 params\ndense/kernel:0: (9408, 512) -> 4816896 params\ndense/bias:0: (512,) -> 512 params\npatch_embedding/conv3d_4/kernel:0: (4, 16, 16, 3, 512) -> 1572864 params\npatch_embedding/conv3d_4/bias:0: (512,) -> 512 params\npositional_encoding:0: (16, 512) -> 8192 params\npositional_encoding:0: (196, 512) -> 100352 params\nmulti_head_attention/query/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention/query/bias:0: (8, 64) -> 512 params\nmulti_head_attention/key/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention/key/bias:0: (8, 64) -> 512 params\nmulti_head_attention/value/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention/value/bias:0: (8, 64) -> 512 params\nmulti_head_attention/attention_output/kernel:0: (8, 64, 512) -> 262144 params\nmulti_head_attention/attention_output/bias:0: (512,) -> 512 params\nmulti_head_attention_1/query/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_1/query/bias:0: (8, 64) -> 512 params\nmulti_head_attention_1/key/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_1/key/bias:0: (8, 64) -> 512 params\nmulti_head_attention_1/value/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_1/value/bias:0: (8, 64) -> 512 params\nmulti_head_attention_1/attention_output/kernel:0: (8, 64, 512) -> 262144 params\nmulti_head_attention_1/attention_output/bias:0: (512,) -> 512 params\nmulti_head_attention_2/query/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_2/query/bias:0: (8, 64) -> 512 params\nmulti_head_attention_2/key/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_2/key/bias:0: (8, 64) -> 512 params\nmulti_head_attention_2/value/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_2/value/bias:0: (8, 64) -> 512 params\nmulti_head_attention_2/attention_output/kernel:0: (8, 64, 512) -> 262144 params\nmulti_head_attention_2/attention_output/bias:0: (512,) -> 512 params\nmulti_head_attention_3/query/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_3/query/bias:0: (8, 64) -> 512 params\nmulti_head_attention_3/key/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_3/key/bias:0: (8, 64) -> 512 params\nmulti_head_attention_3/value/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_3/value/bias:0: (8, 64) -> 512 params\nmulti_head_attention_3/attention_output/kernel:0: (8, 64, 512) -> 262144 params\nmulti_head_attention_3/attention_output/bias:0: (512,) -> 512 params\nlayer_normalization/gamma:0: (512,) -> 512 params\nlayer_normalization/beta:0: (512,) -> 512 params\nlayer_normalization_1/gamma:0: (512,) -> 512 params\nlayer_normalization_1/beta:0: (512,) -> 512 params\nlayer_normalization_2/gamma:0: (512,) -> 512 params\nlayer_normalization_2/beta:0: (512,) -> 512 params\nlayer_normalization_3/gamma:0: (512,) -> 512 params\nlayer_normalization_3/beta:0: (512,) -> 512 params\nlayer_normalization_4/gamma:0: (512,) -> 512 params\nlayer_normalization_4/beta:0: (512,) -> 512 params\nlayer_normalization_5/gamma:0: (512,) -> 512 params\nlayer_normalization_5/beta:0: (512,) -> 512 params\ndense_1/kernel:0: (512, 512) -> 262144 params\ndense_1/bias:0: (512,) -> 512 params\ndense_2/kernel:0: (512, 512) -> 262144 params\ndense_2/bias:0: (512,) -> 512 params\ndense_3/kernel:0: (512, 512) -> 262144 params\ndense_3/bias:0: (512,) -> 512 params\ndense_4/kernel:0: (512, 512) -> 262144 params\ndense_4/bias:0: (512,) -> 512 params\ndense_5/kernel:0: (512, 512) -> 262144 params\ndense_5/bias:0: (512,) -> 512 params\nembedding/embeddings:0: (10000, 512) -> 5120000 params\npositional_encoding:0: (40, 512) -> 20480 params\nmulti_head_attention_4/query/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_4/query/bias:0: (8, 64) -> 512 params\nmulti_head_attention_4/key/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_4/key/bias:0: (8, 64) -> 512 params\nmulti_head_attention_4/value/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_4/value/bias:0: (8, 64) -> 512 params\nmulti_head_attention_4/attention_output/kernel:0: (8, 64, 512) -> 262144 params\nmulti_head_attention_4/attention_output/bias:0: (512,) -> 512 params\nmulti_head_attention_5/query/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_5/query/bias:0: (8, 64) -> 512 params\nmulti_head_attention_5/key/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_5/key/bias:0: (8, 64) -> 512 params\nmulti_head_attention_5/value/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_5/value/bias:0: (8, 64) -> 512 params\nmulti_head_attention_5/attention_output/kernel:0: (8, 64, 512) -> 262144 params\nmulti_head_attention_5/attention_output/bias:0: (512,) -> 512 params\nmulti_head_attention_6/query/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_6/query/bias:0: (8, 64) -> 512 params\nmulti_head_attention_6/key/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_6/key/bias:0: (8, 64) -> 512 params\nmulti_head_attention_6/value/kernel:0: (512, 8, 64) -> 262144 params\nmulti_head_attention_6/value/bias:0: (8, 64) -> 512 params\nmulti_head_attention_6/attention_output/kernel:0: (8, 64, 512) -> 262144 params\nmulti_head_attention_6/attention_output/bias:0: (512,) -> 512 params\ndense_6/kernel:0: (512, 512) -> 262144 params\ndense_6/bias:0: (512,) -> 512 params\ndense_7/kernel:0: (512, 512) -> 262144 params\ndense_7/bias:0: (512,) -> 512 params\ndense_8/kernel:0: (512, 512) -> 262144 params\ndense_8/bias:0: (512,) -> 512 params\ndense_9/kernel:0: (512, 512) -> 262144 params\ndense_9/bias:0: (512,) -> 512 params\ndense_10/kernel:0: (512, 512) -> 262144 params\ndense_10/bias:0: (512,) -> 512 params\nlayer_normalization_6/gamma:0: (512,) -> 512 params\nlayer_normalization_6/beta:0: (512,) -> 512 params\nlayer_normalization_7/gamma:0: (512,) -> 512 params\nlayer_normalization_7/beta:0: (512,) -> 512 params\nlayer_normalization_8/gamma:0: (512,) -> 512 params\nlayer_normalization_8/beta:0: (512,) -> 512 params\nlayer_normalization_9/gamma:0: (512,) -> 512 params\nlayer_normalization_9/beta:0: (512,) -> 512 params\nlayer_normalization_10/gamma:0: (512,) -> 512 params\nlayer_normalization_10/beta:0: (512,) -> 512 params\ndense_11/kernel:0: (512, 10000) -> 5120000 params\ndense_11/bias:0: (10000,) -> 10000 params\nTotal trainable parameters: 26762302\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "    # Define the loss function\n",
        "    cross_entropy = keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction=\"none\"\n",
        "    )\n",
        "\n",
        "    # EarlyStopping criteria\n",
        "    early_stopping = keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n",
        "\n",
        "    class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "        def __init__(self, d_model, warmup_steps=4000):\n",
        "            super(CustomSchedule, self).__init__()\n",
        "\n",
        "            self.d_model = tf.cast(d_model, tf.float32)\n",
        "            self.warmup_steps = warmup_steps\n",
        "\n",
        "        def __call__(self, step):\n",
        "            step = tf.cast(step, tf.float32)\n",
        "            arg1 = tf.math.rsqrt(step)\n",
        "            arg2 = step * (self.warmup_steps ** -1.5)\n",
        "            return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "\n",
        "    # Create the learning rate schedule\n",
        "    lr_schedule = CustomSchedule(EMBED_DIM)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(\n",
        "        learning_rate=lr_schedule,\n",
        "        beta_1=0.9,\n",
        "        beta_2=0.98,\n",
        "        epsilon=1e-9\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=optimizer, loss=cross_entropy)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:29:16.373569Z",
          "iopub.execute_input": "2025-03-27T05:29:16.373770Z",
          "iopub.status.idle": "2025-03-27T05:29:16.962141Z",
          "shell.execute_reply.started": "2025-03-27T05:29:16.373753Z",
          "shell.execute_reply": "2025-03-27T05:29:16.961498Z"
        },
        "id": "SlerMIgvKzmo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model\n",
        "history = model.fit(train_dataset, epochs=EPOCHS, validation_data=valid_dataset, callbacks=[early_stopping])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T05:29:16.963140Z",
          "iopub.execute_input": "2025-03-27T05:29:16.963405Z",
          "iopub.status.idle": "2025-03-27T11:25:20.393579Z",
          "shell.execute_reply.started": "2025-03-27T05:29:16.963372Z",
          "shell.execute_reply": "2025-03-27T11:25:20.392628Z"
        },
        "id": "TyHHfhAcKzmo",
        "outputId": "7f606aaf-6ef9-4839-8592-6c83f124a9b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/100\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1743053454.744211     119 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "124/124 [==============================] - 263s 1s/step - seq_loss: 359.3947 - seq_acc: 0.0388 - val_seq_loss: 270.7645 - val_seq_acc: 0.1452\nEpoch 2/100\n124/124 [==============================] - 217s 1s/step - seq_loss: 244.2375 - seq_acc: 0.2012 - val_seq_loss: 199.2707 - val_seq_acc: 0.2739\nEpoch 3/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 192.8254 - seq_acc: 0.2864 - val_seq_loss: 179.4180 - val_seq_acc: 0.3029\nEpoch 4/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 175.5656 - seq_acc: 0.3156 - val_seq_loss: 164.7331 - val_seq_acc: 0.3244\nEpoch 5/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 161.3196 - seq_acc: 0.3296 - val_seq_loss: 154.5081 - val_seq_acc: 0.3381\nEpoch 6/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 152.6002 - seq_acc: 0.3384 - val_seq_loss: 147.2885 - val_seq_acc: 0.3472\nEpoch 7/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 145.1326 - seq_acc: 0.3519 - val_seq_loss: 141.1869 - val_seq_acc: 0.3434\nEpoch 8/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 137.8139 - seq_acc: 0.3644 - val_seq_loss: 135.5325 - val_seq_acc: 0.3638\nEpoch 9/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 135.4859 - seq_acc: 0.3655 - val_seq_loss: 131.2994 - val_seq_acc: 0.3679\nEpoch 10/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 129.7076 - seq_acc: 0.3742 - val_seq_loss: 126.2012 - val_seq_acc: 0.3784\nEpoch 11/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 126.7001 - seq_acc: 0.3791 - val_seq_loss: 122.6495 - val_seq_acc: 0.3845\nEpoch 12/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 121.6957 - seq_acc: 0.3880 - val_seq_loss: 118.6931 - val_seq_acc: 0.3958\nEpoch 13/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 117.9719 - seq_acc: 0.3968 - val_seq_loss: 114.8691 - val_seq_acc: 0.4014\nEpoch 14/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 115.9113 - seq_acc: 0.3995 - val_seq_loss: 110.9922 - val_seq_acc: 0.4103\nEpoch 15/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 111.8008 - seq_acc: 0.4126 - val_seq_loss: 108.6427 - val_seq_acc: 0.4211\nEpoch 16/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 110.0330 - seq_acc: 0.4169 - val_seq_loss: 105.5512 - val_seq_acc: 0.4292\nEpoch 17/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 106.4694 - seq_acc: 0.4271 - val_seq_loss: 102.4988 - val_seq_acc: 0.4371\nEpoch 18/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 103.8195 - seq_acc: 0.4358 - val_seq_loss: 100.7278 - val_seq_acc: 0.4454\nEpoch 19/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 102.7637 - seq_acc: 0.4375 - val_seq_loss: 97.6566 - val_seq_acc: 0.4535\nEpoch 20/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 100.0850 - seq_acc: 0.4477 - val_seq_loss: 95.8263 - val_seq_acc: 0.4634\nEpoch 21/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 97.1900 - seq_acc: 0.4590 - val_seq_loss: 93.0353 - val_seq_acc: 0.4767\nEpoch 22/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 96.3464 - seq_acc: 0.4612 - val_seq_loss: 89.1153 - val_seq_acc: 0.4909\nEpoch 23/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 93.1734 - seq_acc: 0.4750 - val_seq_loss: 89.8585 - val_seq_acc: 0.4862\nEpoch 24/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 91.2965 - seq_acc: 0.4817 - val_seq_loss: 87.7437 - val_seq_acc: 0.4970\nEpoch 25/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 88.7727 - seq_acc: 0.4935 - val_seq_loss: 84.9001 - val_seq_acc: 0.5095\nEpoch 26/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 87.1871 - seq_acc: 0.4971 - val_seq_loss: 83.1320 - val_seq_acc: 0.5160\nEpoch 27/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 85.2040 - seq_acc: 0.5045 - val_seq_loss: 81.9586 - val_seq_acc: 0.5245\nEpoch 28/100\n124/124 [==============================] - 215s 1s/step - seq_loss: 84.4911 - seq_acc: 0.5091 - val_seq_loss: 79.0041 - val_seq_acc: 0.5340\nEpoch 29/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 81.0986 - seq_acc: 0.5235 - val_seq_loss: 77.7843 - val_seq_acc: 0.5358\nEpoch 30/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 80.1262 - seq_acc: 0.5281 - val_seq_loss: 76.1137 - val_seq_acc: 0.5506\nEpoch 31/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 78.7025 - seq_acc: 0.5387 - val_seq_loss: 72.7079 - val_seq_acc: 0.5649\nEpoch 32/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 78.2808 - seq_acc: 0.5366 - val_seq_loss: 74.4582 - val_seq_acc: 0.5539\nEpoch 33/100\n124/124 [==============================] - 215s 1s/step - seq_loss: 77.3991 - seq_acc: 0.5415 - val_seq_loss: 69.0295 - val_seq_acc: 0.5825\nEpoch 34/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 73.5760 - seq_acc: 0.5603 - val_seq_loss: 70.7909 - val_seq_acc: 0.5759\nEpoch 35/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 74.0359 - seq_acc: 0.5566 - val_seq_loss: 69.2680 - val_seq_acc: 0.5879\nEpoch 36/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 71.7180 - seq_acc: 0.5687 - val_seq_loss: 65.6871 - val_seq_acc: 0.6015\nEpoch 37/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 67.9694 - seq_acc: 0.5851 - val_seq_loss: 61.6131 - val_seq_acc: 0.6153\nEpoch 38/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 66.7229 - seq_acc: 0.5896 - val_seq_loss: 61.2668 - val_seq_acc: 0.6206\nEpoch 39/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 64.8177 - seq_acc: 0.5991 - val_seq_loss: 58.8725 - val_seq_acc: 0.6330\nEpoch 40/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 63.9434 - seq_acc: 0.6041 - val_seq_loss: 59.6018 - val_seq_acc: 0.6323\nEpoch 41/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 63.0960 - seq_acc: 0.6094 - val_seq_loss: 56.2797 - val_seq_acc: 0.6450\nEpoch 42/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 60.3650 - seq_acc: 0.6190 - val_seq_loss: 54.6850 - val_seq_acc: 0.6502\nEpoch 43/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 59.4713 - seq_acc: 0.6214 - val_seq_loss: 54.2196 - val_seq_acc: 0.6591\nEpoch 44/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 57.5913 - seq_acc: 0.6343 - val_seq_loss: 53.6157 - val_seq_acc: 0.6601\nEpoch 45/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 57.0135 - seq_acc: 0.6376 - val_seq_loss: 49.8096 - val_seq_acc: 0.6794\nEpoch 46/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 54.0871 - seq_acc: 0.6485 - val_seq_loss: 48.7513 - val_seq_acc: 0.6865\nEpoch 47/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 53.7065 - seq_acc: 0.6517 - val_seq_loss: 48.0219 - val_seq_acc: 0.6888\nEpoch 48/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 52.1635 - seq_acc: 0.6632 - val_seq_loss: 47.7330 - val_seq_acc: 0.6896\nEpoch 49/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 51.3643 - seq_acc: 0.6635 - val_seq_loss: 46.8445 - val_seq_acc: 0.6908\nEpoch 50/100\n124/124 [==============================] - 215s 1s/step - seq_loss: 50.4328 - seq_acc: 0.6692 - val_seq_loss: 45.4440 - val_seq_acc: 0.7000\nEpoch 51/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 49.4024 - seq_acc: 0.6729 - val_seq_loss: 43.7446 - val_seq_acc: 0.7081\nEpoch 52/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 48.3777 - seq_acc: 0.6773 - val_seq_loss: 43.2652 - val_seq_acc: 0.7140\nEpoch 53/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 46.6809 - seq_acc: 0.6870 - val_seq_loss: 43.6150 - val_seq_acc: 0.7093\nEpoch 54/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 46.8724 - seq_acc: 0.6863 - val_seq_loss: 41.9059 - val_seq_acc: 0.7178\nEpoch 55/100\n124/124 [==============================] - 215s 1s/step - seq_loss: 45.8742 - seq_acc: 0.6910 - val_seq_loss: 40.4386 - val_seq_acc: 0.7260\nEpoch 56/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 44.9231 - seq_acc: 0.6969 - val_seq_loss: 40.6325 - val_seq_acc: 0.7254\nEpoch 57/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 43.3502 - seq_acc: 0.7062 - val_seq_loss: 40.3388 - val_seq_acc: 0.7243\nEpoch 58/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 43.3693 - seq_acc: 0.7035 - val_seq_loss: 40.3519 - val_seq_acc: 0.7256\nEpoch 59/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 43.9381 - seq_acc: 0.6995 - val_seq_loss: 38.3047 - val_seq_acc: 0.7356\nEpoch 60/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 42.2531 - seq_acc: 0.7119 - val_seq_loss: 38.0915 - val_seq_acc: 0.7361\nEpoch 61/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 41.1859 - seq_acc: 0.7176 - val_seq_loss: 39.6113 - val_seq_acc: 0.7305\nEpoch 62/100\n124/124 [==============================] - 215s 1s/step - seq_loss: 42.0299 - seq_acc: 0.7101 - val_seq_loss: 36.4255 - val_seq_acc: 0.7477\nEpoch 63/100\n124/124 [==============================] - 219s 1s/step - seq_loss: 39.9125 - seq_acc: 0.7231 - val_seq_loss: 36.0605 - val_seq_acc: 0.7467\nEpoch 64/100\n124/124 [==============================] - 220s 1s/step - seq_loss: 40.1289 - seq_acc: 0.7216 - val_seq_loss: 36.0169 - val_seq_acc: 0.7492\nEpoch 65/100\n124/124 [==============================] - 220s 1s/step - seq_loss: 38.8252 - seq_acc: 0.7298 - val_seq_loss: 35.5017 - val_seq_acc: 0.7507\nEpoch 66/100\n124/124 [==============================] - 220s 1s/step - seq_loss: 38.7646 - seq_acc: 0.7284 - val_seq_loss: 34.8825 - val_seq_acc: 0.7519\nEpoch 67/100\n124/124 [==============================] - 220s 1s/step - seq_loss: 38.1410 - seq_acc: 0.7324 - val_seq_loss: 35.2253 - val_seq_acc: 0.7514\nEpoch 68/100\n124/124 [==============================] - 219s 1s/step - seq_loss: 37.6495 - seq_acc: 0.7354 - val_seq_loss: 34.7319 - val_seq_acc: 0.7525\nEpoch 69/100\n124/124 [==============================] - 220s 1s/step - seq_loss: 37.6391 - seq_acc: 0.7321 - val_seq_loss: 33.7954 - val_seq_acc: 0.7576\nEpoch 70/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 36.8518 - seq_acc: 0.7381 - val_seq_loss: 33.1644 - val_seq_acc: 0.7618\nEpoch 71/100\n124/124 [==============================] - 214s 1s/step - seq_loss: 37.3135 - seq_acc: 0.7360 - val_seq_loss: 33.5577 - val_seq_acc: 0.7584\nEpoch 72/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 37.0301 - seq_acc: 0.7368 - val_seq_loss: 32.8197 - val_seq_acc: 0.7616\nEpoch 73/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 35.4830 - seq_acc: 0.7456 - val_seq_loss: 32.7823 - val_seq_acc: 0.7613\nEpoch 74/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 35.8564 - seq_acc: 0.7424 - val_seq_loss: 32.1812 - val_seq_acc: 0.7653\nEpoch 75/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 35.5118 - seq_acc: 0.7435 - val_seq_loss: 32.2012 - val_seq_acc: 0.7629\nEpoch 76/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 34.5625 - seq_acc: 0.7490 - val_seq_loss: 31.8979 - val_seq_acc: 0.7651\nEpoch 77/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 34.1284 - seq_acc: 0.7515 - val_seq_loss: 31.1456 - val_seq_acc: 0.7683\nEpoch 78/100\n 60/124 [=============>................] - ETA: 1:07 - seq_loss: 33.1379 - seq_acc: 0.7596Epoch 79/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 34.0011 - seq_acc: 0.7508 - val_seq_loss: 31.0920 - val_seq_acc: 0.7693\nEpoch 80/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 33.8802 - seq_acc: 0.7514 - val_seq_loss: 30.9612 - val_seq_acc: 0.7651\nEpoch 81/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 33.8673 - seq_acc: 0.7524 - val_seq_loss: 30.4777 - val_seq_acc: 0.7698\nEpoch 82/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 32.8426 - seq_acc: 0.7559 - val_seq_loss: 30.2076 - val_seq_acc: 0.7703\nEpoch 83/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 32.7337 - seq_acc: 0.7571 - val_seq_loss: 30.1419 - val_seq_acc: 0.7715\nEpoch 84/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 32.6272 - seq_acc: 0.7568 - val_seq_loss: 30.3732 - val_seq_acc: 0.7712\nEpoch 85/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 32.0302 - seq_acc: 0.7607 - val_seq_loss: 29.5269 - val_seq_acc: 0.7747\nEpoch 86/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 31.9949 - seq_acc: 0.7607 - val_seq_loss: 29.2511 - val_seq_acc: 0.7748\nEpoch 87/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 31.8486 - seq_acc: 0.7605 - val_seq_loss: 28.6863 - val_seq_acc: 0.7795\nEpoch 88/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 31.6377 - seq_acc: 0.7613 - val_seq_loss: 28.9095 - val_seq_acc: 0.7772\nEpoch 89/100\n124/124 [==============================] - 213s 1s/step - seq_loss: 31.0873 - seq_acc: 0.7648 - val_seq_loss: 29.1842 - val_seq_acc: 0.7737\nEpoch 90/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 31.8247 - seq_acc: 0.7610 - val_seq_loss: 31.4428 - val_seq_acc: 0.7631\nEpoch 91/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 32.9840 - seq_acc: 0.7544 - val_seq_loss: 28.6325 - val_seq_acc: 0.7800\nEpoch 92/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 31.2835 - seq_acc: 0.7615 - val_seq_loss: 28.0551 - val_seq_acc: 0.7805\nEpoch 93/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 30.5101 - seq_acc: 0.7654 - val_seq_loss: 28.0904 - val_seq_acc: 0.7794\nEpoch 94/100\n124/124 [==============================] - 210s 1s/step - seq_loss: 30.4405 - seq_acc: 0.7661 - val_seq_loss: 28.1534 - val_seq_acc: 0.7775\nEpoch 95/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 30.2704 - seq_acc: 0.7679 - val_seq_loss: 28.4262 - val_seq_acc: 0.7777\nEpoch 96/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 30.2890 - seq_acc: 0.7678 - val_seq_loss: 27.3118 - val_seq_acc: 0.7811\nEpoch 97/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 29.9193 - seq_acc: 0.7704 - val_seq_loss: 27.5378 - val_seq_acc: 0.7807\nEpoch 98/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 30.0901 - seq_acc: 0.7665 - val_seq_loss: 27.5724 - val_seq_acc: 0.7799\nEpoch 99/100\n124/124 [==============================] - 212s 1s/step - seq_loss: 29.5072 - seq_acc: 0.7715 - val_seq_loss: 27.1967 - val_seq_acc: 0.7815\nEpoch 100/100\n124/124 [==============================] - 211s 1s/step - seq_loss: 29.6785 - seq_acc: 0.7697 - val_seq_loss: 27.3832 - val_seq_acc: 0.7821\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(valid_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T11:25:20.395847Z",
          "iopub.execute_input": "2025-03-27T11:25:20.396793Z",
          "iopub.status.idle": "2025-03-27T11:25:44.342718Z",
          "shell.execute_reply.started": "2025-03-27T11:25:20.396762Z",
          "shell.execute_reply": "2025-03-27T11:25:44.341931Z"
        },
        "id": "YHTd5rQLKzmp",
        "outputId": "1f597e73-4276-422d-85bf-a3aed92a10ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "25/25 [==============================] - 24s 483ms/step - seq_loss: 27.3927 - seq_acc: 0.7825\n",
          "output_type": "stream"
        },
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[0.7821028232574463, 27.38321304321289]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorization.get_vocabulary()\n",
        "index_lookup = dict(zip(range(len(vocab)), vocab))\n",
        "max_decoded_sentence_length = SEQ_LENGTH - 1\n",
        "valid_videos = list(valid_data.keys())\n",
        "\n",
        "def generate_caption(video_path):\n",
        "    if video_path is None:\n",
        "        sample_video = np.random.choice(valid_videos)\n",
        "    else:\n",
        "        sample_video = video_path\n",
        "\n",
        "    video_name = os.path.splitext(os.path.basename(sample_video))[0]\n",
        "    video_storage_path = os.path.join(FRAMES_STORAGE_PATH, video_name)\n",
        "    if not os.path.exists(video_storage_path) or len(os.listdir(video_storage_path)) == 0:\n",
        "        save_video_frames(sample_video, video_storage_path)\n",
        "\n",
        "    video_frames = tf_load_frames_from_directory(video_storage_path)\n",
        "    video_frames = tf.expand_dims(video_frames, axis=0)\n",
        "\n",
        "    encoded_frames = model.encoder(video_frames)\n",
        "\n",
        "    decoded_caption = \"<start>\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_caption = vectorization([decoded_caption])[:, :-1]\n",
        "        mask = tf.math.not_equal(tokenized_caption, 0)\n",
        "\n",
        "        predictions = model.decoder([tokenized_caption, encoded_frames, mask])\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = index_lookup[sampled_token_index]\n",
        "\n",
        "        if sampled_token == \"<end>\":\n",
        "            break\n",
        "\n",
        "        decoded_caption += \" \" + sampled_token\n",
        "\n",
        "    decoded_caption = decoded_caption.replace(\"<start> \", \"\")\n",
        "    decoded_caption = decoded_caption.replace(\" <end>\", \"\").strip()\n",
        "    return decoded_caption\n",
        "\n",
        "def compute_cider(valid_data):\n",
        "    references = {}\n",
        "    hypotheses = {}\n",
        "    val = {}\n",
        "\n",
        "    val = {\n",
        "        key: [text.replace(\"<start> \", \"\").replace(\" <end>\", \"\") for text in value]\n",
        "        for key, value in valid_data.items()\n",
        "    }\n",
        "\n",
        "    for video_path, reference_captions in tqdm(val.items(), desc=\"Compute Score\"):\n",
        "        generated_caption = generate_caption(video_path)\n",
        "\n",
        "        video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "        references[video_name] = reference_captions\n",
        "        hypotheses[video_name] = [generated_caption]\n",
        "\n",
        "    cider_scorer = Cider()\n",
        "    score, _ = cider_scorer.compute_score(references, hypotheses)\n",
        "    return score\n",
        "\n",
        "compute_cider(valid_data)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-27T11:25:44.343723Z",
          "iopub.execute_input": "2025-03-27T11:25:44.343988Z",
          "iopub.status.idle": "2025-03-27T11:29:16.453216Z",
          "shell.execute_reply.started": "2025-03-27T11:25:44.343966Z",
          "shell.execute_reply": "2025-03-27T11:29:16.452312Z"
        },
        "id": "raWocevFKzmp",
        "outputId": "dd2b1d0f-413a-4811-c585-0b469eb542c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "Compute Score: 100%|██████████| 394/394 [03:30<00:00,  1.87it/s]\n",
          "output_type": "stream"
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "1.7464361356254516"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    }
  ]
}